{
 "metadata": {
  "name": "",
  "signature": "sha256:a62207f4cfdcf4f6fef8de5d825ef77a6984e2d0bfeef3fd293f75e2f330fe02"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Bigrams Lemmatizer/Stemmer"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "connect to sqlite DB containing bigrams of wikipedia, wiktionary, and google books(since 1970) and get each bigram lemma/stem using ndk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.stem import PorterStemmer\n",
      "import sqlite3 as sql\n",
      "def stem_bigrams(db_table):    \n",
      "        \n",
      "    # define porter stemmer\n",
      "    stemmer = PorterStemmer()\n",
      "    \n",
      "    # connect to DB\n",
      "    dbpath = '/home/wshalaby/work/patents/patents-similarity/data/CLEF/03-patents-with-5-fixes.db'    \n",
      "    stmt = 'select rowid,bigram from {}' .format(db_table)\n",
      "    con = sql.connect(dbpath)\n",
      "    with con:\n",
      "        # select bigrams from table\n",
      "        cur = con.execute(stmt)\n",
      "        count = 0\n",
      "        while True:\n",
      "            # get next bigram\n",
      "            record = cur.fetchone()\n",
      "            if record==None or record[0]==None or record[1]==None:\n",
      "                break\n",
      "            rowid = record[0]\n",
      "            \n",
      "            # stem bigram (need to stem each word alone as stemmer works only on last word in case of multiword string)\n",
      "            words = record[1].split(' ')\n",
      "            stemmed_bigram = ''\n",
      "            for i in range(len(words)):\n",
      "                if i==0:\n",
      "                    stemmed_bigram = stemmer.stem(words[i])\n",
      "                else:\n",
      "                    stemmed_bigram = stemmed_bigram + ' ' + stemmer.stem(words[i])                \n",
      "            \n",
      "            # update DB\n",
      "            stmt = u'update {} set stem=\"{}\" where rowid={}' .format(db_table,stemmed_bigram,rowid)\n",
      "            con.execute(stmt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.stem import WordNetLemmatizer\n",
      "import sqlite3 as sql\n",
      "def lemmatize_bigrams(db_table):    \n",
      "        \n",
      "    # define porter stemmer\n",
      "    lemmatizer = WordNetLemmatizer()\n",
      "    \n",
      "    # connect to DB\n",
      "    dbpath = '/home/wshalaby/work/patents/patents-similarity/data/CLEF/03-patents-with-5-fixes.db'    \n",
      "    stmt = 'select rowid,bigram from {}' .format(db_table)\n",
      "    con = sql.connect(dbpath)\n",
      "    with con:\n",
      "        # select bigrams from table\n",
      "        cur = con.execute(stmt)\n",
      "        while True:\n",
      "            # get next bigram\n",
      "            record = cur.fetchone()\n",
      "            if record==None or record[0]==None or record[1]==None:\n",
      "                break\n",
      "            rowid = record[0]\n",
      "            \n",
      "            # lemmatize bigram (need to lemmatize each word alone as lemmatizer doesn't works in case of multiword string)\n",
      "            words = record[1].split(' ')\n",
      "            lemmatized_bigram = ''\n",
      "            for i in range(len(words)):\n",
      "                if i==0:\n",
      "                    lemmatized_bigram = lemmatizer.lemmatize(words[i])\n",
      "                else:\n",
      "                  lemmatized_bigram = lemmatized_bigram + ' ' + lemmatizer.lemmatize(words[i])                \n",
      "            \n",
      "            # update DB\n",
      "            stmt = u'update {} set lemma=\"{}\" where rowid={}' .format(db_table,lemmatized_bigram,rowid)\n",
      "            con.execute(stmt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stem_bigrams('wiki_bigrams')\n",
      "print 'wiki_bigrams - stem - done'\n",
      "lemmatize_bigrams('wiki_bigrams')\n",
      "print 'wiki_bigrams - lemma - done'\n",
      "stem_bigrams('wiktionary_bigrams')\n",
      "print 'wiktionary_bigrams - stem - done'\n",
      "lemmatize_bigrams('wiktionary_bigrams')\n",
      "print 'wiktionary_bigrams - lemma - done'\n",
      "stem_bigrams('google_bigrams')\n",
      "print 'google_bigrams - stem - done'\n",
      "lemmatize_bigrams('google_bigrams')\n",
      "print 'google_bigrams - lemma - done'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "wiki_bigrams - stem - done\n",
        "wiki_bigrams - lemma - done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "wiktionary_bigrams - stem - done\n",
        "wiktionary_bigrams - lemma - done\n",
        "google_bigrams - stem - done\n",
        "google_bigrams - lemma - done\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}